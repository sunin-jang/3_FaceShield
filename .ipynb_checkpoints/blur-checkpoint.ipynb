{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version0.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur():\n",
    "    import tensorflow as tf\n",
    "    import cv2\n",
    "    import time\n",
    "    import argparse\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import posenet\n",
    "\n",
    "    # file = 비디오파일 이름(아래와 같이 적으려면 파이썬파일과 비디오파일을 같은 위치에 두세요.)\n",
    "\n",
    "    upload_dir = 'uploads/'\n",
    "    file_list = os.listdir(upload_dir)\n",
    "\n",
    "    file=file_list[0] # file_list의 첫번째 파일\n",
    "\n",
    "    if file is not None:\n",
    "        cap = cv2.VideoCapture(file)\n",
    "    height = int(cap.get(4))\n",
    "    width = int(cap.get(3))   \n",
    "\n",
    "\n",
    "    model = 101\n",
    "    cam_id = 1\n",
    "    cam_width = 1280\n",
    "    cam_height = 720\n",
    "    scale_factor = 0.7125\n",
    "\n",
    "    def set_blur_range(\n",
    "            img, instance_scores, keypoint_scores, keypoint_coords,\n",
    "            min_pose_score=0.5, min_part_score=0.5):\n",
    "        out_img = img\n",
    "        adjacent_keypoints = []\n",
    "        cv_keypoints = []\n",
    "\n",
    "        people_count = []\n",
    "        list_start_blur_y = []\n",
    "        list_end_blur_y = []\n",
    "        list_start_blur_x = []\n",
    "        list_end_blur_x = []\n",
    "\n",
    "        for ii, score in enumerate(instance_scores):\n",
    "            if score < min_pose_score:\n",
    "                continue\n",
    "\n",
    "            new_keypoints = posenet.utils.get_adjacent_keypoints(\n",
    "                keypoint_scores[ii, :], keypoint_coords[ii, :, :], min_part_score)\n",
    "            adjacent_keypoints.extend(new_keypoints)\n",
    "\n",
    "            people_count.append(ii)\n",
    "\n",
    "            kc2 = []\n",
    "            print(ii, \"번째 객체\")\n",
    "\n",
    "            for ks, kc in zip(keypoint_scores[ii, :5], keypoint_coords[ii, :5, :]):\n",
    "                if ks < min_part_score:\n",
    "                    continue\n",
    "                cv_keypoints.append(cv2.KeyPoint(kc[1], kc[0], 10. * ks))\n",
    "                if kc[1] < 0:\n",
    "                    kc2.append([kc[0],1])\n",
    "                elif kc[1] > width:\n",
    "                    kc2.append([kc[0],width-3])\n",
    "                elif kc[0] < 0:\n",
    "                    kc2.append([1, kc[1]])\n",
    "                elif kc[0] > height:\n",
    "                    kc2.append([height-3, kc[1]])\n",
    "                elif kc[0] < 0 and kc[1] < 0:\n",
    "                    kc2.append([1,1])\n",
    "                elif kc[0] > height and kc[1] > width:\n",
    "                    kc2.append([height-3,width-3])\n",
    "                else:\n",
    "                    kc2.append(kc)\n",
    "\n",
    "\n",
    "            if len(kc2) >= 3:\n",
    "            # 코\n",
    "                nose_y = int(kc2[0][0]) # y축\n",
    "                nose_x = int(kc2[0][1]) # x축\n",
    "            # 오른쪽눈\n",
    "                eye_right_y = int(kc2[1][0])\n",
    "                eye_right_x = int(kc2[1][1])\n",
    "            # 왼쪽눈\n",
    "                eye_left_y = int(kc2[2][0])\n",
    "                eye_left_x = int(kc2[2][1])            \n",
    "\n",
    "                print(\"> 1.Nose(y:\",nose_y,\", x:\",nose_x,\")\",\"2.EyeRight(y:\",eye_right_y,\", x:\",eye_right_x,\")\",\n",
    "                      \"3.EyeLeft(y:\",eye_left_y,\", x:\",eye_left_x,\")\") \n",
    "\n",
    "            # y값 최솟값, 최댓값, 중앙값 구하기\n",
    "                value_y = [nose_y, eye_right_y, eye_left_y]\n",
    "                min_value_y = min(value_y)\n",
    "                max_value_y = max(value_y)\n",
    "                mean_value_y = int(sum(value_y)/len(value_y))\n",
    "            # x값 최솟값, 최댓값, 중앙값 구하기\n",
    "                value_x = [nose_x, eye_right_x, eye_left_x]\n",
    "                min_value_x = min(value_x)\n",
    "                max_value_x = max(value_x)\n",
    "                mean_value_x = int(sum(value_x)/len(value_x))\n",
    "\n",
    "            # 블러 크기를 키우기 위한 변수 만들기\n",
    "                value_y_gap = abs(max_value_y-min_value_y)\n",
    "                value_x_gap = abs(max_value_x-min_value_x)\n",
    "\n",
    "            # 블러 씌울 부분 변수 선언\n",
    "                start_blur_y = abs(mean_value_y-int(value_y_gap*1.7))\n",
    "                end_blur_y = mean_value_y+int(value_y_gap*2)\n",
    "                start_blur_x = abs(min_value_x-value_y_gap)\n",
    "                end_blur_x = max_value_x+value_y_gap\n",
    "                if start_blur_x==end_blur_x:\n",
    "                    end_blur_x += 3\n",
    "                if start_blur_y==end_blur_y:\n",
    "                    end_blur_y += 3\n",
    "            # 근만씨 동영상 오류 해결중\n",
    "                if abs(eye_right_x-eye_left_x) > 20:\n",
    "                    start_blur_y = abs(min_value_y-value_y_gap)\n",
    "                    end_blur_y = nose_y+abs(eye_right_x-eye_left_x)+value_y_gap\n",
    "                    start_blur_x = abs(min_value_x-value_x_gap)\n",
    "                    end_blur_x = max_value_x +value_x_gap\n",
    "                print(\"[\",start_blur_y,\":\",end_blur_y,\", \",start_blur_x,\":\",end_blur_x,\"]\")                                 \n",
    "\n",
    "            elif len(kc2) >= 2:\n",
    "            # 코\n",
    "                nose_y = int(kc2[0][0]) # y축\n",
    "                nose_x = int(kc2[0][1]) # x축\n",
    "            # 오른쪽눈\n",
    "                eye_right_y = int(kc2[1][0])\n",
    "                eye_right_x = int(kc2[1][1])      \n",
    "\n",
    "                print(\"> 1.Nose(y:\",nose_y,\", x:\",nose_x,\")\",\"2.EyeRight(y:\",eye_right_y,\", x:\",eye_right_x,\")\") \n",
    "\n",
    "            # y값 최솟값, 최댓값, 중앙값 구하기\n",
    "                value_y = [nose_y, eye_right_y]\n",
    "                min_value_y = min(value_y)\n",
    "                max_value_y = max(value_y)\n",
    "                mean_value_y = int(sum(value_y)/len(value_y))\n",
    "            # x값 최솟값, 최댓값, 중앙값 구하기\n",
    "                value_x = [nose_x, eye_right_x]\n",
    "                min_value_x = min(value_x)\n",
    "                max_value_x = max(value_x)\n",
    "                mean_value_x = int(sum(value_x)/len(value_x))            \n",
    "            # 블러 크기를 키우기 위한 변수 만들기\n",
    "                value_y_gap = abs(max_value_y-int(sum(value_y)/len(value_y)))\n",
    "                value_x_gap = abs(max_value_x-int(sum(value_x)/len(value_x)))\n",
    "\n",
    "            # 블러 씌울 부분 변수 선언\n",
    "                start_blur_y = abs(mean_value_y-int(value_y_gap*1.7))\n",
    "                end_blur_y = mean_value_y+int(value_y_gap*2)\n",
    "                start_blur_x = abs(mean_value_x-value_y_gap)\n",
    "                end_blur_x = mean_value_x+value_y_gap\n",
    "                if start_blur_x==end_blur_x:\n",
    "                    end_blur_x += 3\n",
    "                if start_blur_y==end_blur_y:\n",
    "                    end_blur_y += 3\n",
    "                print(\"[\",start_blur_y,\":\",end_blur_y,\", \",start_blur_x,\":\",end_blur_x,\"]\")\n",
    "\n",
    "            else:\n",
    "            # 블러 씌울 부분 변수 선언\n",
    "                start_blur_y = 0\n",
    "                end_blur_y = 0\n",
    "                start_blur_x = 0\n",
    "                end_blur_x = 0\n",
    "\n",
    "            list_start_blur_y.append(start_blur_y)\n",
    "            list_end_blur_y.append(end_blur_y)\n",
    "            list_start_blur_x.append(start_blur_x)\n",
    "            list_end_blur_x.append(end_blur_x)\n",
    "\n",
    "        return list_start_blur_y,list_end_blur_y,list_start_blur_x,list_end_blur_x, people_count\n",
    "\n",
    "    def main():\n",
    "        with tf.Session() as sess:\n",
    "            model_cfg, model_outputs = posenet.load_model(model, sess)\n",
    "            output_stride = model_cfg['output_stride']\n",
    "\n",
    "            if file is not None:\n",
    "                cap = cv2.VideoCapture(file)\n",
    "            else:\n",
    "                cap = cv2.VideoCapture(cam_id)\n",
    "            cap.set(3, cam_width)\n",
    "            cap.set(4, cam_height)\n",
    "\n",
    "            start = time.time()\n",
    "            frame_count = 0\n",
    "\n",
    "            list_count = 0\n",
    "            start_blur_y_list = []\n",
    "            end_blur_y_list = []\n",
    "            start_blur_x_list = []\n",
    "            end_blur_x_list = []\n",
    "            blur_y_gap_list = []\n",
    "            blur_x_gap_list = []  \n",
    "\n",
    "            # 녹화 기능 설정\n",
    "            fps = 29.92        # 초당 프레임\n",
    "            # 녹화할 이미지 크기\n",
    "            width = int(cap.get(3))   \n",
    "            height = int(cap.get(4))\n",
    "            # 코덱 종류 설정\n",
    "            fcc = cv2.VideoWriter_fourcc('U', '2', '6', '3')\n",
    "\n",
    "            # 설정 된 값으로 동영상 녹화\n",
    "            out = cv2.VideoWriter(\"downloads/{}_blur.mp4\".format(file[:-4]), fcc, fps, (width, height))\n",
    "\n",
    "            while True:\n",
    "                res, img = cap.read()    \n",
    "\n",
    "                if not res:\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    print(\"webcam failure\")   \n",
    "                    break\n",
    "\n",
    "                input_image, display_image, output_scale = posenet.utils._process_input(\n",
    "                    img, scale_factor=scale_factor, output_stride=output_stride)\n",
    "\n",
    "                heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "                    model_outputs,\n",
    "                    feed_dict={'image:0': input_image}\n",
    "                )\n",
    "\n",
    "                pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses(\n",
    "                    heatmaps_result.squeeze(axis=0),\n",
    "                    offsets_result.squeeze(axis=0),\n",
    "                    displacement_fwd_result.squeeze(axis=0),\n",
    "                    displacement_bwd_result.squeeze(axis=0),\n",
    "                    output_stride=output_stride,\n",
    "                    max_pose_detections=10,\n",
    "                    min_pose_score=0.15)\n",
    "\n",
    "                keypoint_coords *= output_scale\n",
    "\n",
    "            # 블러처리한 이미지 범위\n",
    "                list_start_blur_y,list_end_blur_y,list_start_blur_x,list_end_blur_x, people_count = set_blur_range(\n",
    "                    display_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "                    min_pose_score=0.15, min_part_score=0.1)\n",
    "                print(\">\"*10,\"main 함수\",\"<\"*10)\n",
    "                print(\"총 인원수: \",len(people_count))\n",
    "\n",
    "                for start_blur_y,end_blur_y,start_blur_x,end_blur_x,i in zip(list_start_blur_y,list_end_blur_y,list_start_blur_x,list_end_blur_x,people_count):\n",
    "\n",
    "                    if start_blur_y!=0 and end_blur_y!=0 and start_blur_x!=0 and end_blur_x!=0:\n",
    "                        start_blur_y_list.append(start_blur_y)\n",
    "                        end_blur_y_list.append(end_blur_y)\n",
    "                        start_blur_x_list.append(start_blur_x)\n",
    "                        end_blur_x_list.append(end_blur_x)\n",
    "\n",
    "                        blur_y_gap = abs(end_blur_y-start_blur_y)\n",
    "                        blur_x_gap = abs(end_blur_x-start_blur_x)\n",
    "                        blur_y_gap_list.append(blur_y_gap)\n",
    "                        blur_x_gap_list.append(blur_x_gap)\n",
    "\n",
    "                    #블러 씌우는 부분\n",
    "                        img_blur = display_image[start_blur_y:end_blur_y, start_blur_x:end_blur_x]\n",
    "                        img_blur = cv2.blur(img_blur, (20,20), anchor=(-1, -1), borderType=cv2.BORDER_DEFAULT)\n",
    "                        display_image[start_blur_y:end_blur_y, start_blur_x:end_blur_x] = img_blur\n",
    "\n",
    "                    elif start_blur_y==0 and end_blur_y==0 and start_blur_x==0 and end_blur_x==0:\n",
    "\n",
    "                        display_image = img\n",
    "\n",
    "                print(\"-\"*60,'frame ',frame_count,\"-\"*60)\n",
    "                cv2.imshow('posenet', display_image)\n",
    "                # 동영상 녹화\n",
    "                out.write(display_image)\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "                # 숫자 1 을 누르면 창이 닫혀요.\n",
    "                if cv2.waitKey(1) == 49:\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "\n",
    "            print('Average FPS: ', frame_count / (time.time() - start))\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SM32\\Anaconda3\\envs\\pro3_GPU\\lib\\site-packages\\posenet\\converter\\config.py:8: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(cfg_f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find model file ./_models\\model-mobilenet_v1_101.pb, converting from tfjs...\n",
      "Weights for checkpoint mobilenet_v1_101 are not downloaded. Downloading to C:\\Users\\SM32\\AppData\\Local\\Temp\\_posenet_weights ...\n",
      "Downloading MobilenetV1_Conv2d_0_biases\n",
      "Downloading MobilenetV1_Conv2d_0_weights\n",
      "Downloading MobilenetV1_Conv2d_10_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_10_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_10_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_10_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_11_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_11_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_11_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_11_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_12_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_12_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_12_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_12_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_13_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_13_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_13_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_13_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_1_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_1_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_1_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_1_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_2_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_2_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_2_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_2_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_3_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_3_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_3_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_3_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_4_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_4_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_4_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_4_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_5_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_5_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_5_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_5_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_6_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_6_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_6_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_6_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_7_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_7_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_7_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_7_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_8_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_8_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_8_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_8_pointwise_weights\n",
      "Downloading MobilenetV1_Conv2d_9_depthwise_biases\n",
      "Downloading MobilenetV1_Conv2d_9_depthwise_depthwise_weights\n",
      "Downloading MobilenetV1_Conv2d_9_pointwise_biases\n",
      "Downloading MobilenetV1_Conv2d_9_pointwise_weights\n",
      "Downloading MobilenetV1_displacement_bwd_1_biases\n"
     ]
    }
   ],
   "source": [
    "blur()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
